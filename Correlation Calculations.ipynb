{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38e8e9-fdb3-495f-a2a9-581584f1295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024, Edward Jakunskas, Department of Electronic Engineering, Maynooth University\n",
    "#\n",
    "# Maintainer: Edward Jakunskas (edward.jakunskas@mu.ie)\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# 1. Redistributions of source code must retain the above copyright notice, this\n",
    "#    list of conditions and the following disclaimer.\n",
    "#\n",
    "# 2. Redistributions in binary form must reproduce the above copyright notice, this\n",
    "#    list of conditions and the following disclaimer in the documentation\n",
    "#    and/or other materials provided with the distribution.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e9cc1856-d168-4308-9ab1-39ca8b4cddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-08-29-Morning/processed_LiCOR_data_cleaned.xlsx\n",
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-08-29-Evening/processed_LiCOR_data_cleaned.xlsx\n",
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-09-02-Evening/processed_LiCOR_data_cleaned.xlsx\n",
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-09-03-Morning/processed_LiCOR_data_cleaned.xlsx\n",
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-09-03-Evening/processed_LiCOR_data_cleaned.xlsx\n",
      "Processed and saved data to: /workspace/Data/GH4-Completed/2024-09-04-Morning/processed_LiCOR_data_cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#base path where all files are stored and licor file prefix\n",
    "base_path = '/workspace/Data/GH4-Completed'\n",
    "file_prefix = 'Auto gsw+F_'  #Prefix for the licor measurements files\n",
    "\n",
    "#List of daily directories\n",
    "daily_dirs = ['2024-08-29-Morning', '2024-08-29-Evening',\n",
    "              '2024-09-02-Evening', '2024-09-03-Morning',\n",
    "              '2024-09-03-Evening', '2024-09-04-Morning']\n",
    "\n",
    "#relevant licro metrics to extract\n",
    "columns_of_interest = ['gsw', 'gtw', 'VPleaf', 'VPDleaf', 'H2O_leaf', 'Fs', \"Fm'\", 'abs', 'TRANS', 'Tleaf']\n",
    "\n",
    "#use this fucntion to find licor excel files with a certain rpefix\n",
    "def find_file_with_prefix(directory, prefix):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.startswith(prefix) and file.endswith('.xlsx'):\n",
    "            return os.path.join(directory, file)\n",
    "    return None\n",
    "\n",
    "#Function to load, process Li-COR data, handle merged cells, filter columns, bascially cleaning up to calcualte correlations easily\n",
    "def process_individual_licor_data(base_path, daily_dirs, file_prefix, columns_of_interest):\n",
    "    for date_dir in daily_dirs:\n",
    "        directory_path = os.path.join(base_path, date_dir)\n",
    "        \n",
    "        #find the file that starts with the licor prefix\n",
    "        file_path = find_file_with_prefix(directory_path, file_prefix)\n",
    "        \n",
    "        if file_path and os.path.exists(file_path):\n",
    "            licor_data = pd.read_excel(file_path, header=1)  #Uses the second row as headers\n",
    "\n",
    "            #rename the first column to pot id manually since merged cells affect header\n",
    "            licor_data.rename(columns={licor_data.columns[0]: 'Pot ID'}, inplace=True)\n",
    "\n",
    "            #ffill down the pot id column where there are merged cells\n",
    "            licor_data['Pot ID'].fillna(method='ffill', inplace=True)\n",
    "            \n",
    "            #select cleaned pot id's and columns of interest \n",
    "            licor_data = licor_data[['Pot ID'] + columns_of_interest]\n",
    "            \n",
    "            #get average reading for each pot id\n",
    "            licor_data_avg = licor_data.groupby('Pot ID').mean().reset_index()\n",
    "            \n",
    "            #Save the processed data to the respective directory\n",
    "            save_path = os.path.join(directory_path, 'processed_LiCOR_data_cleaned.xlsx')\n",
    "            licor_data_avg.to_excel(save_path, index=False)\n",
    "            print(f\"Processed and saved data to: {save_path}\")\n",
    "        else:\n",
    "            print(f\"File not found with prefix '{file_prefix}' in {directory_path}\")\n",
    "\n",
    "#Process each Li-COR file individually and save the results to the respective directories\n",
    "process_individual_licor_data(base_path, daily_dirs, file_prefix, columns_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28a4ca0-490d-482b-b330-3a711c625185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8564/2114992210.py:85: NearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n",
      "  corr_value, p_value = pearsonr(median_camera[camera_col], li_cor_data[licor_col])\n",
      "/tmp/ipykernel_8564/2114992210.py:85: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr_value, p_value = pearsonr(median_camera[camera_col], li_cor_data[licor_col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 correlations for Li-COR Metric: gsw\n",
      "1. HI Mean vs gsw | Correlation: -0.38872745184204616, p-value: 0.00015291273656362853\n",
      "2. NGRDI Min vs gsw | Correlation: -0.3743179789308916, p-value: 0.00027849472208608055\n",
      "3. HI Q3 vs gsw | Correlation: -0.3737042024344305, p-value: 0.00028552402457794054\n",
      "4. HI Median vs gsw | Correlation: -0.37036391888143816, p-value: 0.0003267266514710615\n",
      "5. HI Mode vs gsw | Correlation: -0.3671110982675979, p-value: 0.0003720411491392104\n",
      "Top 5 correlations for Li-COR Metric: gtw\n",
      "1. HI Mean vs gtw | Correlation: -0.3892020933220807, p-value: 0.00014985154337750483\n",
      "2. HI Q3 vs gtw | Correlation: -0.3740846063030888, p-value: 0.00028114843795281973\n",
      "3. HI Median vs gtw | Correlation: -0.3709741783049636, p-value: 0.000318813063462927\n",
      "4. HI Mode vs gtw | Correlation: -0.3685490153530486, p-value: 0.0003513414487242904\n",
      "5. NGRDI Min vs gtw | Correlation: -0.3655897097595036, p-value: 0.00039515762398214583\n",
      "Top 5 correlations for Li-COR Metric: VPleaf\n",
      "1. GREEN Range vs VPleaf | Correlation: -0.5558752482126514, p-value: 1.289414579047001e-08\n",
      "2. GREEN Min vs VPleaf | Correlation: 0.5274904010124041, p-value: 9.196716013377348e-08\n",
      "3. BLUE Range vs VPleaf | Correlation: -0.5216777930326714, p-value: 1.3455008225841655e-07\n",
      "4. BLUE Min vs VPleaf | Correlation: 0.5143590484071401, p-value: 2.1508697722384574e-07\n",
      "5. RED Range vs VPleaf | Correlation: -0.513575771479247, p-value: 2.2601453859809554e-07\n",
      "Top 5 correlations for Li-COR Metric: VPDleaf\n",
      "1. GREEN Range vs VPDleaf | Correlation: -0.5205384006690239, p-value: 1.4484921413615974e-07\n",
      "2. GREEN Min vs VPDleaf | Correlation: 0.4920941116810922, p-value: 8.393033928485794e-07\n",
      "3. BLUE Range vs VPDleaf | Correlation: -0.4859359151325203, p-value: 1.2028660676013034e-06\n",
      "4. BLUE Min vs VPDleaf | Correlation: 0.4811704101768448, p-value: 1.5815943623095345e-06\n",
      "5. RED Range vs VPDleaf | Correlation: -0.4790919525920059, p-value: 1.7798570230163062e-06\n",
      "Top 5 correlations for Li-COR Metric: H2O_leaf\n",
      "1. GREEN Range vs H2O_leaf | Correlation: -0.5572093062630412, p-value: 1.1703356969858253e-08\n",
      "2. GREEN Min vs H2O_leaf | Correlation: 0.5286609949875294, p-value: 8.510932428006225e-08\n",
      "3. BLUE Range vs H2O_leaf | Correlation: -0.5233053078993026, p-value: 1.2103895170773868e-07\n",
      "4. BLUE Min vs H2O_leaf | Correlation: 0.5155128257262207, p-value: 1.9990014881668017e-07\n",
      "5. RED Range vs H2O_leaf | Correlation: -0.5148862982109603, p-value: 2.0801581727368894e-07\n",
      "Top 5 correlations for Li-COR Metric: Fs\n",
      "1. a_channel Std Dev vs Fs | Correlation: 0.38114599206160715, p-value: 0.00021034642722353496\n",
      "2. a_channel Variance vs Fs | Correlation: 0.3641732561017296, p-value: 0.00041785787648013006\n",
      "3. TGI Std Dev vs Fs | Correlation: 0.3497963645364729, p-value: 0.0007261700661388157\n",
      "4. TGI Variance vs Fs | Correlation: 0.3470261413610882, p-value: 0.0008053895683794599\n",
      "5. HI Q1 vs Fs | Correlation: 0.3250463434423758, p-value: 0.001772606901842663\n",
      "Top 5 correlations for Li-COR Metric: Fm'\n",
      "1. BLUE Mode vs Fm' | Correlation: -0.3432288357911666, p-value: 0.0009267999945769701\n",
      "2. GREEN Q1 vs Fm' | Correlation: -0.33645865483026693, p-value: 0.0011853173928374505\n",
      "3. BLUE Q1 vs Fm' | Correlation: -0.33034478289857433, p-value: 0.0014733020197749212\n",
      "4. GREEN Skewness vs Fm' | Correlation: 0.3193893746085006, p-value: 0.0021518533031771587\n",
      "5. GREEN Median vs Fm' | Correlation: -0.31173190701223713, p-value: 0.002781422892766814\n",
      "Top 5 correlations for Li-COR Metric: abs\n",
      "1. RED Q1 vs abs | Correlation: 0.07150968790226092, p-value: 0.5030007964841466\n",
      "2. RED Median vs abs | Correlation: 0.07135008107326733, p-value: 0.5039568292540882\n",
      "3. GREEN Mode vs abs | Correlation: 0.07050784347450856, p-value: 0.5090173336216572\n",
      "4. RED Mean vs abs | Correlation: 0.06930036610711088, p-value: 0.5163177275400647\n",
      "5. RED Mode vs abs | Correlation: 0.06523466092609788, p-value: 0.5412851930025157\n",
      "Top 5 correlations for Li-COR Metric: Tleaf\n",
      "1. GREEN Range vs Tleaf | Correlation: -0.5600624185018684, p-value: 9.499198006800267e-09\n",
      "2. GREEN Min vs Tleaf | Correlation: 0.5282289526837919, p-value: 8.758173508961322e-08\n",
      "3. BLUE Range vs Tleaf | Correlation: -0.5261195832041361, p-value: 1.00666255999801e-07\n",
      "4. RED Range vs Tleaf | Correlation: -0.5187646294108708, p-value: 1.6238662803773493e-07\n",
      "5. BLUE Min vs Tleaf | Correlation: 0.5148643009374261, p-value: 2.0830636548835741e-07\n",
      "Total significant correlations: 42\n",
      "Total number of camera metrics with at least 1 significant correlation: 12\n",
      "Total correlations: 1053\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#base folder and daily directories we'll loop through\n",
    "base_path = '/workspace/Data/GH4-Completed'\n",
    "\n",
    "daily_dirs = ['2024-08-29-Morning',\n",
    "              '2024-09-03-Morning',\n",
    "              '2024-09-04-Morning']\n",
    "\n",
    "li_cor_file_name = 'processed_LiCOR_data_cleaned.xlsx'\n",
    "camera_file_name = 'merged_file_with_pages.xlsx'\n",
    "\n",
    "#lists to collect combined camera and li-cor data\n",
    "all_median_camera_data = []\n",
    "all_li_cor_data = []\n",
    "\n",
    "#load licor data for a specific date\n",
    "def get_licor_data(base_path, date_dir, li_cor_file_name):\n",
    "    file_path = os.path.join(base_path, date_dir, li_cor_file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "        df['Pot ID'] = df['Pot ID'].astype(str) + f\"_{date_dir}\"  #combining pot ID and date to have unique correlations for each pot/date\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File '{li_cor_file_name}' not found in {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#loading camera data for a specific sheet on a specific date\n",
    "def load_camera_data(base_path, date_dir, sheet_name):\n",
    "    file_path = os.path.join(base_path, date_dir, camera_file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df.rename(columns={df.columns[0]: 'Pot ID'}, inplace=True)  #manually naming first column to Pot ID as this wasn't done in previous code, can ignore if fixed\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Camera file '{camera_file_name}' not found in {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#matchign and sortign the pots betwen the licor and camera sheets\n",
    "def match_and_sort_pots(camera_sheets, li_cor_data, date_dir):\n",
    "    camera_filtered_sheets = []\n",
    "    \n",
    "    # Iterate through each camera sheet and filter by matching Pot IDs\n",
    "    for camera_sheet in camera_sheets:\n",
    "        camera_sheet['Pot ID'] = camera_sheet['Pot ID'].astype(str) + f\"_{date_dir}\" #licor date appended while reading licor file\n",
    "        \n",
    "        # find pot IDs that also exist in licor data, then sort by p[ot ID so it lines up with licor data\n",
    "        camera_filtered = camera_sheet[camera_sheet['Pot ID'].isin(li_cor_data['Pot ID'])].sort_values('Pot ID')\n",
    "        camera_filtered_sheets.append(camera_filtered)\n",
    "\n",
    "    # remove licor data that isn' tin matching camera data, sort by pot ID also\n",
    "    all_pot_ids = pd.concat([camera_sheet['Pot ID'] for camera_sheet in camera_sheets])\n",
    "    li_cor_filtered = li_cor_data[li_cor_data['Pot ID'].isin(all_pot_ids)].sort_values('Pot ID')\n",
    "    #returning list of matched and sorted camera and licor data\n",
    "    return camera_filtered_sheets, li_cor_filtered\n",
    "\n",
    "\n",
    "#computing the median value of each pot angle as a simple way to remove outliers\n",
    "def median_camera_sheets(camera_filtered_sheets):\n",
    "    concatenated_df = pd.concat([sheet.select_dtypes(include=[np.number]) for sheet in camera_filtered_sheets],\n",
    "                                keys=range(len(camera_filtered_sheets)))\n",
    "\n",
    "    median_df = concatenated_df.groupby(level=1).median()\n",
    "    return median_df\n",
    "\n",
    "\n",
    "# Find Pearson correlations between camera and Li-COR data, tested spearmans' ranked correlations and found the correlation is more linear\n",
    "def find_correlations_pearson(median_camera, li_cor_data):\n",
    "    correlations = {}\n",
    "    \n",
    "    #select only the numeric columns, excluding 'Pot ID'\n",
    "    camera_numeric_columns = median_camera.select_dtypes(include=[np.number]).columns\n",
    "    licor_numeric_columns = li_cor_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    for camera_col in camera_numeric_columns:\n",
    "        for licor_col in licor_numeric_columns:\n",
    "            corr_value, p_value = pearsonr(median_camera[camera_col], li_cor_data[licor_col])\n",
    "            if not np.isnan(corr_value):\n",
    "                correlations.setdefault(licor_col, []).append((camera_col, corr_value, p_value))\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "#helper function\n",
    "def process_correlation(camera_col, licor_col, corr_value, p_value, num_tests, bonferroni_threshold, significant_camera_metrics, normalized_correlations_list):\n",
    "    # Adjust the p-value with Bonferroni correction\n",
    "    adjusted_p_value = min(p_value * num_tests, 1)  # Ensure p-value doesn't exceed 1\n",
    "    is_significant = adjusted_p_value < 0.05\n",
    "    \n",
    "    # Append significant metrics and correlations\n",
    "    if is_significant:\n",
    "        significant_camera_metrics.add(camera_col)\n",
    "    \n",
    "    # Save correlation data to the list\n",
    "    normalized_correlations_list.append({\n",
    "        'LiCOR Metric': licor_col,\n",
    "        'Camera Metric': camera_col,\n",
    "        'Correlation': corr_value,\n",
    "        'Original P-value': p_value,\n",
    "        'Adjusted P-value': adjusted_p_value,\n",
    "        'Bonferroni Threshold': bonferroni_threshold,\n",
    "        'Significant': 'Yes' if is_significant else 'No'\n",
    "    })\n",
    "    \n",
    "def plot_and_save(camera_col, licor_col, corr_value, p_value, median_camera, li_cor_data, output_dir, plot_index):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(median_camera[camera_col], li_cor_data[licor_col], alpha=0.5)\n",
    "    plt.title(f'{camera_col} vs {licor_col}\\nCorrelation: {corr_value:.2f}, p-value: {p_value:.3g}')\n",
    "    plt.xlabel(camera_col)\n",
    "    plt.ylabel(licor_col)\n",
    "    plt.grid(True)\n",
    "    plot_file_name = f'{camera_col}_vs_{licor_col}_corr_{plot_index + 1}.png'.replace('/', '_')\n",
    "    plt.savefig(os.path.join(output_dir, plot_file_name))\n",
    "    plt.close()\n",
    "    \n",
    "def plot_significant_correlations_per_licor(correlations, median_camera, li_cor_data, n=5, num_tests=1, output_dir='correlation_plots', output_file='normalized_significant_correlations.csv'):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    bonferroni_threshold = 0.05 / num_tests\n",
    "    normalized_correlations_list = []\n",
    "    significant_camera_metrics = set()\n",
    "    total_significant_correlations = 0\n",
    "    total_correlations = 0\n",
    "\n",
    "    for licor_col, correlation_data in correlations.items():\n",
    "        sorted_correlations = sorted(correlation_data, key=lambda x: abs(x[1]), reverse=True)\n",
    "        print(f\"Top {n} correlations for Li-COR Metric: {licor_col}\")\n",
    "\n",
    "        for i, (camera_col, corr_value, p_value) in enumerate(sorted_correlations):\n",
    "            process_correlation(camera_col, licor_col, corr_value, p_value, num_tests, bonferroni_threshold, significant_camera_metrics, normalized_correlations_list)\n",
    "            total_correlations += 1\n",
    "            if i < n:\n",
    "                print(f\"{i+1}. {camera_col} vs {licor_col} | Correlation: {corr_value}, p-value: {p_value}\")\n",
    "                plot_and_save(camera_col, licor_col, corr_value, p_value, median_camera, li_cor_data, output_dir, i)\n",
    "\n",
    "    normalized_correlations_df = pd.DataFrame(normalized_correlations_list)\n",
    "    normalized_correlations_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Total significant correlations: {len([d for d in normalized_correlations_list if d['Significant'] == 'Yes'])}\")\n",
    "    print(f\"Total number of camera metrics with at least 1 significant correlation: {len(significant_camera_metrics)}\")\n",
    "    print(f\"Total correlations: {total_correlations}\")\n",
    "\n",
    "\n",
    "# Main loop: process each date\n",
    "for date_dir in daily_dirs:\n",
    "    li_cor_data = get_licor_data(base_path, date_dir, li_cor_file_name)\n",
    "    \n",
    "    if li_cor_data is not None:\n",
    "        camera_sheets = [load_camera_data(base_path, date_dir, sheet) for sheet in \n",
    "                         ['Horizontal-Right', 'Horizontal-Left', 'Angled-45-Right', 'Angled-45-Left']]\n",
    "\n",
    "        if any(sheet is None for sheet in camera_sheets):\n",
    "            print(f\"Skipping {date_dir} due to missing camera sheets.\") #check if anything missing\n",
    "            continue\n",
    "        \n",
    "        camera_filtered_sheets, li_cor_filtered = match_and_sort_pots(camera_sheets, li_cor_data, date_dir)\n",
    "        median_camera = median_camera_sheets(camera_filtered_sheets)\n",
    "        \n",
    "        all_median_camera_data.append(median_camera)\n",
    "        all_li_cor_data.append(li_cor_filtered)\n",
    "\n",
    "#Combine all daily data\n",
    "combined_median_camera = pd.concat(all_median_camera_data, ignore_index=True)\n",
    "combined_li_cor_data = pd.concat(all_li_cor_data, ignore_index=True)\n",
    "\n",
    "#Find correlations\n",
    "correlations = find_correlations_pearson(combined_median_camera, combined_li_cor_data)\n",
    "\n",
    "#Plot the top correlations\n",
    "plot_significant_correlations_per_licor(\n",
    "    correlations, \n",
    "    combined_median_camera, \n",
    "    combined_li_cor_data, \n",
    "    n=5,  # Show top 5 correlations in plots\n",
    "    num_tests=117,  # 117 tests, this is a bug that is present in paper, should be 117*8, which results in 42 significant correlations instead of 111, but bonferonni seems too strict for this data, so this needs to be resolved shortly regardless\n",
    "    output_dir='correlation_plots_cleaned_v2', \n",
    "    output_file='normalized_significant_correlations_cleaned_v2.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
